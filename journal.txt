2015-08-28 09:49 : copying all configuration files into git repository, so that I can switch computers and my tools get configured quickly and easily.

2015-08-28 10:27 The first thing I did was to put my configuration files into a git repository.
The problem I face is that I oftem move between computers and I get frustrated when the tool does not
do what I expect it to do.
So one method that I could think of was to move my configuration files with me. So I will be putting all config files
into this repository. Then I'll update a small bash script that will pull the latest version of the config files from github
and copy those the the locations where the tools will expect them.
If I want to make any changes to the configuration files my work flow will be following.

1- Go to the folder with this git repository
2- update the relevant configuration file
3- push the changes to git hub ( use 'pushconfig.sh')
4- update the config on the local computer ( run 'configtools.sh')

2015-08-28 10:54 Today I started exploring more about @Atom @text @editor.
I found @electron framework based on node.js.
@electron @allows us to write @desktop applications using @javascript.
@electron will compile the @javascript and build an native application with that code.
What really interested me is that @Atom @text @editor is built using @electron. and it is a great
text editor. What's really intersting is that a lot of contributors can easily write @plugin for it.
And it all can be done using javascript means that all the javascript libraries built over time
become useful. Alhtough other languages have excellent libraries and one can make complex applications with them
what is interesting in case of electron is that it renders the desktop application using a @web @browser with integrated
javascript engine. Thaus all the javascirpt that is on the web can be potentially pulled into the application and executed
as part of it.

This allows us to build front end of our web app in javascript and yet keep the possibility open that at some time we can
turn this front end to a desktop application.

2015-08-28 11:32 electron basically provides a native run time for javascript.
It also exposes native API to javascript, thus javascirpt libraries can call
other libraries.
@electron uses a V8 @javascript engine and @chrome redering engine to give us a tiny webbrwoser that can act as one desktop application.

While exploring electron I also found 'grunt' build tool for javascript. Its very much like 'make' for javascript.
It performs repetie tasks of formating, cleaning, minifying and building packages for javascirpt.

I also found 'Docker'. docker is basically provides an implementation for deploying software on cloud platforms in the form of docker containers.
docker containers are very much like virtual machine but they are light wait, do not require installation of an operating system.
The apps in the container run in a protected environment with all the dependencies available to them in their own conatiners.
Thus two apps that use different versions of the same dependency can run in two different containers and their dependencies do not cause conflicts.

2015-08-28 12:03 The next thing I realized that in order to build good software some common @design @patterns should be understood.
These patterns are in general not dependant on the language being used but some languages are more
convenient in implementing patters.
I ran a search for books on design patters and found some suggestions on @quora.
Here is one interesting resource to look for more information.

http://aosabook.org/en/index.html

2015-08-28 12:13 I just read about the callback in javascript.
JavaScript uses asnychronous events. We can define functions that execute when a certain event occurs.
The time at which the call back function gets called is not deterministic and not determined by the line
of code in which it appears in the soruce code.
It is very much like interrupts. When an interrupt occurs a interrupt routine (dubbed as callback function in javascirpt) gets called and when callback function finishes
the execution of program goes back to the original point where the execution was interrupted.

Callbacks do aysnchronous input/output. In linux kernel when a process is doing input and output, if the related buffers are not ready, the kernel put the process in sleep
and starts executing other processes. When the kernel notices that an I/O operation has finished and a process is sleeping waiting for it, the kernel wakes up the process
and process resumes execution. This effectively blocks the process. If the process has only one thread than it will not respond untill its I/O request is completed.
For processes with multiple threads, a thread can do the I/O and sleep in wait, but other threads of process can continue executing as normal.

Javascript interpretters do a similar thing. They act like multi-threaded processes. If one thread is waiting for I/O, we specify a function that it will call when the I/O has finished.
But other parts of javascript are in execution when this particular io thread is waiting.

2015-08-28 12:19 Although Asynchrnous javascript calls are nice but I don't understand the underlying mechanism.
I think goroutines are more understandble for doing this type of programming.
if we expect a function to take time executing, we launch it in a new goroutine and be done with it.
Golang will start a new thread and will execute the function in that thread.
Thus its easier to understand even in syntax because a function preceded by a keyword 'go' is all we need to specify.

normalfunction(args);   // execution blocks untill the function returns

go normalfunction(args); // A new thread is created for this function and execution of current thread does not block.

2015-08-28 12:20 help

2015-08-28 12:35 Next explore @websockets for duplex communication between @browser and @server app.
I need a reliable javascript websockets library on the client side.
On the server side I think golang will have all the support for websockets.

2015-08-29 13:17 From now on, I'll learn everyday a few things about
--vim
--golang

2015-08-29 18:26 I am just wondering in the land of programming languages.
I just found some criticisms of golang here:

http://yager.io/programming/go.html

This made me realise that @golang might be a great language for certain
needs but it has its limitations.
I have already learnt some @haskell and found that I am not ready for it and
it does not allow the flexibility that I might need especially when it comesto mutating variable values.
So I learnt a little bit of @rust programming language. I am not sure if that is a great language but I have heard that it is systems programming lanugage which is what I am interested in.
It not only provides a static type system and polymorphism like haskell but
it allows us to easily make objects mutable.
So I just learnt a  few basics.
I got the installer.sh using 'curl' and then 'sh installer'.
it installed 'rustc' which is the compiler for rust.
it also installed 'cargo' which is package manager and build system for
rust.
I wrote hello world program in rust.

2015-08-29 18:29 After writeng the hello world program, I used 'cargo' to build and execute the programs. cargo is the build tool for rust programming
language. It uses 'Cargo.toml' file to store all configuration information.
It manages dependencies for the project.
The thing I liked about carg is that it did type checking on 'Cargo.toml'
file itself and caught many errors before it allowed me to build the hello
world program. I hate Javascript because it just silently fails and then
goes on as if nothing happened. This comment is not just about static type
checking but also that type checking is performed on configuration files.
I have not seen a build system that performs type checking on the
configuration files.

2015-08-29 23:59 This is the second time I installed a @vim @plugin using @vim-plug.
The process if fairly simple.
We add to .@vimrc the following line

Plug 'dir/plugname.vim'

Then we source .vimrc or restart vim.
After that we issue the following command
:PlugInstall
@vim-plug will download the plugin and will install it.

Also remember to put '@filetype on' directive at the end of .vimrc when all
plugins have been loaded.

2015-08-30 00:01 : installed the rust.vim for rust language.

2015-08-30 00:07 : created a symlink of .vimrc in journal to home directory.
.vimrc in home directory is just a link to this .vimrc.

2015-08-30 01:40 I just learnt that @vimplug  uses @github to download plugins for @vim.
 If we want a plugin that is avaialable on vim on url
 'http://github.com/authorsgit/pluginproject/plugin/plugin.vim'
 then all we need to specify is a directive in .vimrc

 Plug 'authorsgit/pluginproject'

 After that if we source .vimrc
 or repopen vim and issue the following command

 :PlugInstall

 @vimplug will figureout the whole url and wil download the plugin
 will put it in an approperiate directory.

2015-08-30 02:13 I just discovered a problem with rustlang shoadowing.
rustlang allows us to
shadow variable bindings.
My program declares astring variable 'str'.
Then the program goes into loop.
In the loop the program reads a line from stdin.
then the program does ' let str ; u32 = str.trim().parse();'
Now this line shadows str which originally had type 'String' and now
str has type 'u32'.
The loop finises and then program tries to read stdin into str.
The compiler does not issue any warnings or eorros but a run time error
occurs which terminates the program.
I think compiler should have caught the type mismatch. It made me think
about the safety of rustlang.

2015-08-30 18:37 I found wercker.
@werker is similar to a @build system that integrates with source control
system such as @github and @bitbucket. Every time a commit is pushed to
github, wercker gets a notification that source has changed. Wercker pulls
the new version of source and executes a pipeline of commands for @building,
@testing and @deploying the build (if build is sucessful) on the @target.
Thus the developer can focus on the app and automate the build and deploy
process. The developer only needs to intervene if a build fails and bugs
need to be removed before next successful build.

2015-09-01 20:19 I have been @exploring front end @web design.
 This is growing very rapidly. I have already read about twitter @bootstrp.
 The new thing I found was Google's @polymer which allows us to use @HTML5
 web components even in those browsers which currently do not have support for
 web components. It achieves this by using @polyfills which are @javacript libraries
 that provides necessary functionality for web components if the browser does not
 provide it. If the browser has this functionality, then polymer will let the browser handle
 web components.

 Web components allow html imports, custom html elements, templates and shadow DOM.
 I am not fully aware of there power but I think they make web development much simpler
 and developer can be much more productive.

 Then I watched a video in @polymercasts on youtube. I like this series and I'll be following it.
https://www.youtube.com/results?search_query=polymercasts

 In this video the authos introducd several interesting technologies. These are
 1- Google dev editor
 2- A camera set up on the tablet with tablets being screen captured. The screen capture is then mixed
 with the camera video to build a composite video that is very good for classroom style teaching.
 I found this relevent to @kawish.
 3- The he talked about Yeoman. @Yeoman is a scafollding system that can rapidly build a scaffold for
 you web application. It support polymer and many others, for example angularjs.

 I looked at the workflow of @Yeoman and found that it integrates nicely with
 package and dependency
 managers like @npm and @bower and then build, test and deploy systems like @grunt and @gulp.

http://yeoman.io/learning/

so the work flow is 3 steps
1- Build a scaffolding using Yoeman:

yo polymer

will build a scaffolding for polymer project.

The download dependencies and packages

bower search
bower install

will do that.
Finally when your app is ready

grunt serve
grunt test
grunt

will do the rest.
All done using 6 commands on command line. Impressive.

2015-09-05 02:07 This morning, I did some plotting with @matlab/octave and explored @surf
@plots for ploting surfaces. The task was to plot a cube whose colors can be set
as desired, say rubic cube with large number of rows and columns.
I generated a @meshgrid of a plane and then plotted 6 surfaces of planes that made six
sides of the cube. I discovered how @colormap([vec]) could be used with plots to
to control color of surfaces. I did not start with high expectations from octave/
@matlab but in the end their plotting capabilities were sufficient.
Moreover, I became aware that under the hood they use @OpenGL. So I don't need to
use openGL at very low level. why should I not use it at high level of octave when it
is available.

2015-09-05 02:24 After returning from office I decided to study @HTTP protocol.
I thought that it is ubiqutous protocol in computer @networks so
I should get more understanding of it instead of just relying on high
level tools.
I found a C program for sending a HTTP message to a server. I started
a simple HTTP server that I had installed using npm with nodejs.
(Note that nodejs enables us to write native code using javascript thus we
can write command line programs in javascript).
anyway, running the server was easy, it ran on port 3000.
I then edited the C program and noticed the program flow:
 1- the hostname of server is a string, we send this string to DNS server and
 in return we get the ip address of the server. The ip address is stored in a
 predefined structure in C library.
 2- We prepare a HTTP message string. This string must conform to the HTTP
 standard. the carriage retruns CR '\r' and Line feeds LF '
' must be inserted
 very carefully as required by the standard.
 3- We open a new socket to remote server by using the IP address structure and
 specifying the port number at which the server is listening for incoming connections.
 This is a system call to kernel. The kernel prepares all the data structures to set up this socket and returns a
 file descriptor for the socket.
 We can then read/write this socket as a file.
 3- We connect the socket. This is again a system call. The kernel attempts to set up a TCP
 connection with the server. If the connection is successful, we can start communicating with the server.
 4- To communicate with the server, we write strings (HTTP requests) to the socket as if it was a file.
 5- The server on its end can read the socket and finds the strings that were written by us.
 6- The server parses the strings as HTTP messages. If it can successfully understand the message then
 it prepares a response message and writes it to the socket.
 7- Our program, after having written the HTTP request to the socket, issues a read() system call. This
 call cuases the process to sleep untill there is data available for reading. So our process sleeps while
 the server is preparing a response.
 8- When server has written a response to the socket on its own end and the data arrives at our end,
 then kernel wakes up our process and hands in the data that is returned as a response to the system
 call.
 9- Our process can now parse the response as an HTTP response.

 The things to note are that if you want to write HTTP clients or servers, you must study the HTTP
 specifications in detail. It is the only way you can know exactly how to construct HTTP message strings
 as a client and exactly how to respond to HTTP queries as a server.

2015-09-05 02:36 For HTTP I found a good introductory @resource here.
http://www.jmarshall.com/easy/http/

For indpeth understanding of HTTP, one must read RFC @2616 here:
https://www.ietf.org/rfc/rfc2616.txt
@curl
I used 'curl' to issue HTTP requests to the running server.
I noticed that the server I was using did not adhere to the RFC 2616
for many use cases. It was a simple server so I didn't worry much but
some people were saying that this server could be used in production, which
is something I won't agree to if server does not correctly respond
to all messages according to the standard.

anyway 'curl' is really useful tool. I learnt how to specify requests using --request
flag. How to specify HTTP headers using ' -H " testheaderkey: testheadervalue"'.
I also learnt how to use HTTP proxy using -X option in curl.
I also learnt how to dump body of HTTP message sent and received by curl by using '-o /dev/null'
and how to display the headers sent and received by using '-v' flags.

So learning curl gives me even better understanding of HTTP. curl can use other protocols
and not just HTTP so it is very useful tool.
Then I explored further and found that curl comes a dynamically linked library
called 'libcurl' which can be linked with C programs. curl also has a @library for Python
 and has @bindings for almost all programming languages. Recently someone wrote bindings for
 golang. Although goland already has 'net/http' standard library so libcurl might not be as
 crucial but it can be useful.

2015-09-05 02:55 I was wondering how do computers generate string representations of numbers.
I have used this feature many times in many programming languages but I never
though how it was done.
So I wrote a program that takes a number ( could be contents of a register or
memory location) and then builds a string that represents that number
in human readable form. For example '00001001' will be converted to '9'.
The trick is:
1- Divide the number by base (say 10) and calculate remainder and quotient.
2- Use the remainder to as a lookup index into a string of digits '0123456789ABCDEF'.
and write the char found as the output string. For example if remainder=4, we write
'4' to the output string. The output is built in reverse order as compared to normal strings.
3- Check the quotient, if is zero, stop and declare the output string as final.
If quotient is not zero, then go to step 1 and repeat.

Then I wrote a shell script that called this program to calculate the number in all bases
from 2 to 16.
It was a good learning experience. I never thought that something that we take for granted
can be tricky to calculate if we have never thought about it.
The reverse problem is also interesting. i.e, given a string of digist, find its computer representation
as the contents of a register or memory location.
I think this can be done by reversing the process above.

1- Read the last char of string. Say it is '5'.
2- We set the content of register = 5 ( how?)
   The character representation of '0' is 0x30. So if we take '0' as a number
   and subtract 0x30 from it, we get the registe contents of number 0.
  Now ascii representation of '5' is 0x35 so subtracting 0x30 gives us number 5.EASY.
  just put character in a register and subtract 0x30 from it. the new contents of register will
  be the number that the character represented.

3- Put this number in accamulator. In the input string, look ahead if there is another numberic char
to the left of character we have just processed. If yes, read the character, get its number representation
in temp.
Then accamulator = accamulator * 10 + temp
and continue this process untill you have read all characters in the string.
The final result will the the number in the register.

2015-09-05 03:11 In an HTTP request if we include a header 'If-Modified-Since:  <date and time> '
Then server will check if the resource we are requesting has changed after the
date we have specified in the request. If it has not changed, the server will send
a response with status 304 like this

HTTP/1.1 304 Not Modified

instead of sending the resource in the body (the body will be empty). How can it be useful?

it is useful because if a client had acquired a resource at a given date
and wants to update the resource, all it needs to do is send an HTTP GET request with
"If-Modified-Since: <date>" header. If the server has a newer version, it will send to
the requesting client, otherwise it will not send anything and client will know that
its local cached copy is up-to-date. It saves bandwidth by not sending resources that
have been cached already.

2015-09-05 03:18 For more up-to-date iformation about http see
http://www.w3.org/Protocols/
Especially RFC 723x series of specifications by IETF.

2015-09-05 03:29 Time stamp @standard is
@ISO8601

in addition for HTTP
@RFC723x
@RFC2616

This can be useful for @CENG application.

2015-09-05 13:41 I just noticed that my commits to github were going
with different user names. It is not a problem for me right now
but I decided to investigate and found that I had not been configuring
git before first use. So now that I have configured git properly 
git before first use. So now that I have configured git properly
on my home computer, github show my commit under my github account name.
let's see.

2015-09-02 09:47 Just started to explore React.js.
React gives functionality to update web pages whose information is changing continusouly.
It updates parts of the page/document that have changed as it gets new updates from server or from local events.
Its rather easy to use and all you need is to import two javascripts in the page.
react can also use its own systx JXS but can work with javascript syntax as well.
React can be useful for building apss, such as live event updates, chat and monitoring.
